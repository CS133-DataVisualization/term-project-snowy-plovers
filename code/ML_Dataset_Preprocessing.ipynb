{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Preprocessing\n",
        "\n",
        "\n",
        "*   Since our previous data exploration showed the need for more predictors, we will be merging more datasets\n",
        "*   Handling missing values\n",
        "* Ultimately creating one cohesive + cleaned dataset that we can use for pipelines + ML models\n",
        "\n"
      ],
      "metadata": {
        "id": "WLii2S_Zus7W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pFCKA9HrqTQ",
        "outputId": "bbbcb617-3998-44e3-8ac2-331d2ea304c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "merged_OP: (13220, 51)\n",
            "events:    (3339, 37)\n",
            "nesting:   (846, 68)\n",
            "chicks:    (370, 20)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "merged_OP = pd.read_csv(\"/content/drive/MyDrive/Snowy Plover Datasets/merged_OP.csv\")\n",
        "\n",
        "# More datasets\n",
        "df_events  = pd.read_csv(\"/content/drive/MyDrive/Snowy Plover Datasets/SFAN_SNPL_Events.csv\")\n",
        "df_nesting = pd.read_csv(\"/content/drive/MyDrive/Snowy Plover Datasets/SFAN_SNPL_Nesting.csv\")\n",
        "df_chicks  = pd.read_csv(\"/content/drive/MyDrive/Snowy Plover Datasets/SFAN_SNPL_ChickBands.csv\")\n",
        "df_bands   = pd.read_csv(\"/content/drive/MyDrive/Snowy Plover Datasets/SFAN_SNPL_Bands.csv\")\n",
        "\n",
        "print(\"merged_OP:\", merged_OP.shape)\n",
        "print(\"events:   \", df_events.shape)\n",
        "print(\"nesting:  \", df_nesting.shape)\n",
        "print(\"chicks:   \", df_chicks.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that start_date is datetime in the previous merged dataset\n",
        "if \"Start_Date\" in merged_OP.columns:\n",
        "    merged_OP[\"Start_Date\"] = pd.to_datetime(merged_OP[\"Start_Date\"], errors = \"coerce\")\n",
        "    merged_OP[\"Year\"] = merged_OP[\"Start_Date\"].dt.year\n",
        "    merged_OP[\"Month\"] = merged_OP[\"Start_Date\"].dt.month\n",
        "    merged_OP[\"DayOfYear\"] = merged_OP[\"Start_Date\"].dt.dayofyear\n",
        "\n",
        "# Events dates\n",
        "if \"Start_Date\" in df_events.columns:\n",
        "    df_events[\"Start_Date\"] = pd.to_datetime(df_events[\"Start_Date\"], errors=\"coerce\")\n",
        "if \"Start_Year\" in df_events.columns:\n",
        "    df_events[\"Year\"] = df_events[\"Start_Year\"]\n",
        "\n",
        "# Nesting important dates\n",
        "for col in [\"Date_Found\", \"Hatching_Date\", \"Fledging_Date\", \"Failure_Date\"]:\n",
        "    if col in df_nesting.columns:\n",
        "        df_nesting[col] = pd.to_datetime(df_nesting[col], errors=\"coerce\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fDrfwPTGvP8Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge events dataset\n",
        "\n",
        "event_cols = [\"Event_ID\", \"Survey_Direction\", \"Wind_Spd_mph\",\"Wind_Max_mph\", \"Wind_Dir\", \"Air_Temp_degF\",\n",
        "    \"Rel_Hum_per\",\n",
        "    \"Cloud_Cover\",\n",
        "    \"Tide_Cond\",\n",
        "    \"Incomplete_Survey\"\n",
        "]\n",
        "\n",
        "df_events_small = df_events.loc[:, [c for c in event_cols if c in df_events.columns]]\n",
        "df_events_small = df_events_small.drop_duplicates(subset = [\"Event_ID\"])\n",
        "\n",
        "merged_env = merged_OP.merge(df_events_small, on = \"Event_ID\", how = \"left\")\n",
        "print(\"Shape after events merge:\", merged_env.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVbHTF-BvfFY",
        "outputId": "d3637836-77b7-4cbf-c389-d8015d664167"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after merge: (13220, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge nesting dataset\n",
        "\n",
        "if \"Nest_ID\" in merged_env.columns:\n",
        "    nest_cols = [\"Nest_ID\",  \"Eggs\", \"Hatchlings\",  \"Fledglings\",  \"Failure_Reason\", \"Predator_Type\", \"Restored_Area\"]\n",
        "    nest_cols = [c for c in nest_cols if c in df_nesting.columns]\n",
        "\n",
        "    df_nest_small = df_nesting[nest_cols].drop_duplicates(subset = [\"Nest_ID\"])\n",
        "\n",
        "    # Check is fledglings is working\n",
        "    if \"Fledglings\" in df_nest_small.columns:\n",
        "        df_nest_small[\"NestSuccess\"] = (df_nest_small[\"Fledglings\"].fillna(0) > 0).astype(int)\n",
        "\n",
        "    merged_env_nest = merged_env.merge(df_nest_small, on = \"Nest_ID\", how = \"left\")\n",
        "else:\n",
        "    merged_env_nest = merged_env.copy()\n",
        "\n",
        "print(\"Shape after nesting merge:\", merged_env_nest.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukuXx7NFvrhj",
        "outputId": "30bb62aa-8d3e-4f3c-cab9-9153558215ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after nesting merge: (13220, 68)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge chickbands aggregates\n",
        "\n",
        "if \"Nest_ID\" in df_chicks.columns and \"Nest_ID\" in merged_env_nest.columns:\n",
        "    df_chicks[\"EggToothPresentFlag\"] = df_chicks[\"EggToothPresence\"].astype(str)\\\n",
        "        .str.contains(\"Yes\", case = False, na = False).astype(int)\n",
        "\n",
        "    chick_agg = (\n",
        "        df_chicks.groupby(\"Nest_ID\")\n",
        "        .agg(\n",
        "            NumChicks_Banded    = (\"Chick_BandData_IDInt\", \"count\"),\n",
        "            MeanChickWeight_g   = (\"ChickWeight_g\", \"mean\"),\n",
        "            Pct_Chicks_EggTooth = (\"EggToothPresentFlag\", \"mean\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    merged_full = merged_env_nest.merge(chick_agg, on = \"Nest_ID\", how = \"left\")\n",
        "else:\n",
        "    merged_full = merged_env_nest.copy()\n",
        "\n",
        "print(\"Shape after Chickband merge:\", merged_full.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOAsmhBFwEb1",
        "outputId": "9f534ef2-b251-4eba-887b-458bf8de6812"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after Chickband merge: (13220, 71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generic features usable for future models\n",
        "\n",
        "# Total plovers in that event\n",
        "snpl_cols = [\"SNPL_Male\", \"SNPL_Female\", \"SNPL_Unk\", \"SNPL_Hatchlings\", \"SNPL_Fledglings\"]\n",
        "for c in snpl_cols:\n",
        "    if c not in merged_full.columns:\n",
        "        merged_full[c] = 0\n",
        "\n",
        "merged_full[\"Total_SNPL\"] = merged_full[snpl_cols].sum(axis=1)\n",
        "\n",
        "#Verifying predator present\n",
        "if \"Predator_Present\" in merged_full.columns:\n",
        "    merged_full[\"Predator_Present\"] = merged_full[\"Predator_Present\"].fillna(False)\n"
      ],
      "metadata": {
        "id": "iBEFUkElweA4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing values / missing inputs\n",
        "\n",
        "df = merged_full\n",
        "\n",
        "# Fill the count like columns\n",
        "count_like_cols = [\"SNPL_Male\", \"SNPL_Female\", \"SNPL_Unk\", \"SNPL_Hatchlings\", \"SNPL_Fledglings\", \"Total_SNPL\",\"NumPredator\", \"Eggs\", \"Hatchlings\", \"Fledglings\",\n",
        "    \"NumChicks_Banded\"]\n",
        "\n",
        "for c in count_like_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Fill with median in continuous columns\n",
        "continuous_cols = [ \"Air_Temp_degF\", \"Rel_Hum_per\", \"Wind_Spd_mph\", \"Wind_Max_mph\", \"MeanChickWeight_g\", \"Pct_Chicks_EggTooth\"]\n",
        "\n",
        "for c in continuous_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "        median_val = df[c].median()\n",
        "        df[c] = df[c].fillna(median_val)\n",
        "\n",
        "# Deal with booleans\n",
        "bool_like_cols = [\"Predator_Present\", \"Incomplete_Survey\", \"NestSuccess\", \"Restored_Area\"]\n",
        "for c in bool_like_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = df[c].map({True: True, False: False, \"Yes\": True, \"No\": False}).fillna(False)\n",
        "        df[c] = df[c].astype(bool)\n",
        "\n",
        "# Fill with unknown\n",
        "cat_cols = [ \"Loc_Name\", \"Loc_Code\",\"Tide_Cond\", \"Wind_Dir\", \"Survey_Direction\",\"Failure_Reason\", \"Predator_Type\", \"Observers\"\n",
        "]\n",
        "\n",
        "for c in cat_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = df[c].astype(str).str.strip()\n",
        "        df[c] = df[c].replace({\"nan\": np.nan, \"None\": np.nan})\n",
        "        df[c] = df[c].fillna(\"Unknown\")\n",
        "        df[c] = df[c].astype(\"category\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMFziE3Nwn_p",
        "outputId": "afda2f3d-d264-4f1e-d256-3d27a49ee9ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-976887777.py:26: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].map({True: True, False: False, \"Yes\": True, \"No\": False}).fillna(False)\n",
            "/tmp/ipython-input-976887777.py:26: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].map({True: True, False: False, \"Yes\": True, \"No\": False}).fillna(False)\n",
            "/tmp/ipython-input-976887777.py:26: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].map({True: True, False: False, \"Yes\": True, \"No\": False}).fillna(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving cleaned dataset\n",
        "\n",
        "cleaned_df = df.copy()\n",
        "\n",
        "cleaned_path = \"/content/drive/MyDrive/Snowy Plover Datasets/cleaned_plover_dataset.csv\"\n",
        "cleaned_df.to_csv(cleaned_path, index = False)\n",
        "\n",
        "print(\"Saved cleaned dataset to:\", cleaned_path)\n",
        "print(\"Final shape:\", cleaned_df.shape)\n",
        "print(\"Columns:\", cleaned_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jhZ5-CrxOTe",
        "outputId": "097c8606-50d6-4e2d-9a03-2e212b37b61d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned dataset to: /content/drive/MyDrive/Snowy Plover Datasets/cleaned_plover_dataset.csv\n",
            "Final shape: (13220, 71)\n",
            "Columns: ['ID', 'SNPL_Data_ID', 'Event_ID', 'Type', 'Basis_Of_Record', 'Unit_Code', 'Location_ID', 'Loc_Code', 'Loc_Name', 'Start_Year', 'Start_Date', 'Nest_ID', 'SNPL_Time', 'SNPL_Time_Local', 'Local_Time_Zone', 'QCFlag', 'QCNotes', 'Waypoint', 'Decimal_Latitude', 'Decimal_Longitude', 'Coord_System', 'Datum', 'Scientific_Name', 'SNPL_Male', 'SNPL_Female', 'SNPL_Unk', 'SNPL_Hatchlings', 'SNPL_Fledglings', 'SNPL_Bands', 'Number_Eggs', 'BehaviorTerritoryCC', 'BehaviorTerritoryLW', 'BehaviorTerritoryMD', 'BehaviorTerritorySC', 'BehaviorTerritoryCP', 'BehaviorNestCP', 'BehaviorNestDC', 'BehaviorNestAI', 'BehaviorNestFN', 'BehaviorChicksAC', 'BehaviorChicksNA', 'BehaviorOtherFG', 'SNPL_Notes', 'Year', 'PredatorType', 'CommonName', 'NumPredator', 'PredatorAction', 'Predator_Present', 'Total_SNPL', 'Month', 'DayOfYear', 'Survey_Direction', 'Wind_Spd_mph', 'Wind_Max_mph', 'Wind_Dir', 'Air_Temp_degF', 'Rel_Hum_per', 'Cloud_Cover', 'Tide_Cond', 'Incomplete_Survey', 'Eggs', 'Hatchlings', 'Fledglings', 'Failure_Reason', 'Predator_Type', 'Restored_Area', 'NestSuccess', 'NumChicks_Banded', 'MeanChickWeight_g', 'Pct_Chicks_EggTooth']\n"
          ]
        }
      ]
    }
  ]
}